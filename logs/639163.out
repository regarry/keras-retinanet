c025n02
2024-12-06 15:03:16.407373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-06 15:03:40.162877: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-06 15:03:45.050213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2024-12-06 15:03:45.050299: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-12-06 15:06:08.672383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2024-12-06 15:06:08.673265: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2024-12-06 15:06:08.673317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-12-06 15:08:33.549307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/regarry/.local/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2024-12-06 15:08:33.562486: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-12-06 15:08:33.562637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c025n02): /proc/driver/nvidia/version does not exist
2024-12-06 15:08:53.490876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /usr/local/usrapps/lsmsmart/regarry/retinanet/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
Creation of the directory /rsstu/users/t/tghashg/MADMbrains/Ryan/11-07-2024/mahdi_first_p5/numorph/cell_detection failed
processing 1 of 45 tiles
Creation of the directory /rsstu/users/t/tghashg/MADMbrains/Ryan/11-07-2024/mahdi_first_p5/numorph/cell_detection/305900_277500_result failed
Traceback (most recent call last):
  File "inferenceStitch.py", line 396, in <module>
    fullimg_c1 = read_image_bgr(testpath)
  File "/gpfs_common/share02/lsmsmart/regarry/keras-retinanet/keras_retinanet/utils/image.py", line 32, in read_image_bgr
    image = cv2.imread(path, cv2.IMREAD_UNCHANGED) # modified for uint16 input
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@c025n02>
Subject: Job 639163: <#!/bin/bash;#BSUB -n 8;#BSUB -W 72:00;#BSUB -R "rusage[mem=5GB]";#BSUB -R "span[hosts=1]";#BSUB -o ./logs/%J.out;#BSUB -e ./logs/%J.out;source ~/.bashrc;source /usr/share/Modules/init/bash;#module load cuda/12.0;conda activate /usr/local/usrapps/$GROUP/$USER/retinanet # enter the full path to the conda environment;#conda activate /rsstu/users/t/tghashg/MADMbrains/Ryan/conda/unet ;hostname;#nvidia-smi;#nvcc --version;#python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"; python inferenceStitch.py> in cluster <Hazel> Exited

Job <#!/bin/bash;#BSUB -n 8;#BSUB -W 72:00;#BSUB -R "rusage[mem=5GB]";#BSUB -R "span[hosts=1]";#BSUB -o ./logs/%J.out;#BSUB -e ./logs/%J.out;source ~/.bashrc;source /usr/share/Modules/init/bash;#module load cuda/12.0;conda activate /usr/local/usrapps/$GROUP/$USER/retinanet # enter the full path to the conda environment;#conda activate /rsstu/users/t/tghashg/MADMbrains/Ryan/conda/unet ;hostname;#nvidia-smi;#nvcc --version;#python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"; python inferenceStitch.py> was submitted from host <login03> by user <regarry> in cluster <Hazel> at Fri Dec  6 15:01:50 2024
Job was executed on host(s) <8*c025n02>, in queue <single_chassis>, as user <regarry> in cluster <Hazel> at Fri Dec  6 15:01:50 2024
</home/regarry> was used as the home directory.
</share/lsmsmart/regarry/keras-retinanet> was used as the working directory.
Started at Fri Dec  6 15:01:50 2024
Terminated at Fri Dec  6 15:16:35 2024
Results reported at Fri Dec  6 15:16:35 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -n 8
#BSUB -W 72:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o ./logs/%J.out
#BSUB -e ./logs/%J.out
source ~/.bashrc
source /usr/share/Modules/init/bash
#module load cuda/12.0
conda activate /usr/local/usrapps/$GROUP/$USER/retinanet # enter the full path to the conda environment
#conda activate /rsstu/users/t/tghashg/MADMbrains/Ryan/conda/unet 
hostname
#nvidia-smi
#nvcc --version
#python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

python inferenceStitch.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   3976.50 sec.
    Max Memory :                                 2 GB
    Average Memory :                             0.91 GB
    Total Requested Memory :                     5.00 GB
    Delta Memory :                               3.00 GB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                137
    Run time :                                   903 sec.
    Turnaround time :                            885 sec.

The output (if any) is above this job summary.

